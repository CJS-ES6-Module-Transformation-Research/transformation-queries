\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed
%\usepackage{epstopdf}

\usepackage{algorithm}
\usepackage{mathtools} % for paired limiters
\usepackage{amsmath}
\usepackage[noend]{algpseudocode}
\usepackage{algorithmicx}
\usepackage[hyphens]{url}
\usepackage[hidelinks]{hyperref}
\hypersetup{breaklinks=true}
\urlstyle{same}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\DeclarePairedDelimiter\brac{(\\} {)\\}

\algnewcommand\algorithmicInput{\textbf{Input:}}
\algnewcommand\Input{\item[\algorithmicInput]}

\algnewcommand\algorithmicOutput{\textbf{Output:}}
\algnewcommand\Output{\item[\algorithmicOutput]}

\newcommand\abs[1]{\left|#1\right|}

\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}
\renewcommand{\thealgorithm}{}

\setlength{\textfloatsep}{0.1cm}

\title{\LARGE \bf Multi-Objective Root Growth Optimization}
%
% Single address.
% ---------------

%
% Single address.
% ---------------

\begin{document}
%
\maketitle
\thispagestyle{empty}
\pagestyle{empty}
%
\begin{abstract}
Some of the greatest advancements in heuristic problem solving are inspired from nature. Particle Swarm Optimization (PSO) \cite{PSOPaper} is one such example, which has spawned an entire area of research and countless improvements and offshoots. Another nature-inspired algorithm, the Root Growth Optimization (RGO) \cite{RGOPaper} algorithm, was developed in 2015 to solve single-objective optimization problems. In this paper, we propose an extension to RGO, dubbed MORGO, to adapt it for multi-objective optimization, or the simultaneous optimization of two or more objective functions. We show that MORGO is comparable with a performant contemporary algorithm based on PSO in low dimensions, and generally outperforms a wide variety of other nature-inspired techniques.
\end{abstract}
%
\begin{keywords}
Multi-Objective Optimization, Root Growth Optimization, Multi-Objective Root Growth Optimization
\end{keywords}
%
\section{Introduction}
\label{sec:intro}

Nature-inspired optimization algorithms have proven to be very powerful problem solving tools. Seminal algorithms such as Particle Swarm Optimization (PSO) \cite{PSOPaper} and the Ant Colony System (ACS) \cite{ACSPaper} have given rise to entire fields of research. These algorithms are often heuristic in nature, largely due to the inherent difficulty of the problems they are attempting to solve (for example, ACS is built to propose solutions to the Travelling Salesman Problem, one of the quintessentially ``hard'' problems in Computer Science), and there is no shortage of biological metaphors as sources of inspiration.

In this paper, we consider the Root Growth Optimization algorithm (RGO) \cite{RGOPaper}, a heuristic algorithm designed to find optima for a single function. We propose an extension to RGO, dubbed Multi-Objective Root Growth Optimization (MORGO), which adapts RGO to the problem of multi-objective optimization: optimizing multiple functions simultaneously over the same variable space. 

\section{Optimization}

Optimization is a well studied topic, with a plethora of applications.  Although optimizing a function is in many cases a simple task, locating the position of the global optima is infeasible to compute analytically for some functions, and many heuristic approaches exist for these cases.  In this section, we will briefly explore some of these heuristic methods for optimizing single functions (Single-Objective Optimization), before diving into the simultaneous optimization of several functions (Multi-Objective Optimization).

\subsection{Single-Objective Optimization}
One of the most well-known heuristic optimization algorithms is Particle Swarm Optimization (PSO) \cite{PSOPaper}.  There have also been many biologically inspired adaptations to this algorithm, including the Firefly Algorithm \cite{FireflyPaper} and the Bat Algorithm \cite{BatsPaper}, as well as some other biologically inspired approaches to single-objective optimization which are not centrally based on PSO.  In this paper we will be focusing on one of these in particular - Root Growth Optimization (RGO) as presented in \cite{RGOPaper}.

RGO is an optimization algorithm inspired by the nature of roots.  It differs from PSO and the PSO derivative algorithms in its way of considering the searching agents. Whereas PSO uses a fixed number of mobile particles which change location at each iteration, roots are immobile and correspondingly the agents in RGO remain in a fixed position.  Rather than mobile particles exploring the variable space, RGO can essentially be outlined as follows:
\begin{enumerate}
\item Start with a specified number of root apices;
\item Divide these into $mainRoots$, $lateralRoots$, and $agingRoots$ by their fitness values (computed as the function evaluations at their positions);
\item $mainRoots$ split into more apices and grow (towards the global best);
\item Some of these new $mainRoots$ are pruned;
\item $lateralRoots$ grow (towards the global best);
\item $agingRoots$ do nothing; the bottom 25\% are pruned;
\item For each iteration, return to step 2. 
\end{enumerate}  

The authors of RGO incorporate many biological elements of root growth into their model.  In particular, the root regrowth, pruning, and splitting are implemented considering biological factors \cite{RGOPaper}.  These are presented as operators as follows:
\begin{itemize}
\item \textbf{Regrowing}: this is responsible for the root apex growing forward, towards a particular position.  The equation controlling this growth is similar to that of the PSO movement equation, and is presented as follows: $${ x_i^t = x_i^{t-1} + l \cdot rand(\ )\ \cdot (\ x_{l\texttt{best}} - x_i^{t-1} )\ }$$ where $x_i^{t-1}$ is the previous position of the root apex, $x_{l\texttt{best}}$ is the position of the global best root apex, and $rand$ returns a value between 0 and 1 with uniform probability.  Here $l$ is presented as the ``local learning constant'', and is set as a constant 1 in their parameter listing \cite{RGOPaper}.
\item \textbf{Branching}: this is responsible for the branching of a main root into more daughter apices.  New apices are positioned around their mother root following a Gaussian distribution $N (\ x_i^t, \sigma_i^2 )\ $, where $x_i^t$ is the position of the mother node.  The standard deviation $\sigma_i$ is defined $$ \sigma_i = \left( \frac{i_{max} - i}{i_{max}} \right)^n \cdot (\ \sigma_{ini} - \sigma_{fin} )\ + \sigma_{fin} $$ where $i$ is the current iteration number, and $i_{max}$ is the maximum number of iterations the algorithm is specified to run for.  Unfortunately, $\sigma_{ini}$ and $\sigma_{fin}$ do have neither values specified in the parameter listing, nor a manner of computing them.  Similarly, the parameter $n$ is completely unspecified.  In our implementation of the RGO algorithm, we chose these parameters empirically; the effect of this is discussed below.
\item \textbf{Inhibition Mechanism of Plant Hormones}: this is responsible for the pruning of the new $mainRoots$.  The setup is meant to mimic the limited resources which occur when multiple root apices share the same nutrient space; as presented by \cite{RGOPaper}, in nature roots avoid too much ``root explosion'' near one particular position by emitting inhibition hormones from current apices, to avoid the growth of too many other apices nearby.  This number of new apices which should be inhibited is computed as a percentage of the new apices sprouted.
\end{itemize}

These operators serve to add a measure of biological realism to the RGO algorithm, in justifying the mechanics of the model in terms of root activity as observed in nature.  However, there is a downside to this additional complexity not present in simpler optimization strategies such as PSO: as the number of computations per iteration is increased, the execution time of the algorithm suffers.  This effect is discussed quantitatively in the Results section.

Considering the big picture, the result is similar to that of the particle-based optimization strategies in that the positions of the root apices converge to an optimum over time, although the approach is based on a different theory.

\subsection{Multi-Objective Optimization}
Multi-objective optimization is an extension of the single-objective case considered above.  Rather than finding the global optimum of one function, this deals with simultaneously optimizing multiple functions which all share the same variable space.  

The added complication is that there is no longer a guarantee that there exists a single global optimum.  Since each of the functions have their own optima which may be located at different positions, multi-objective optimization is more about finding a compromise between these.  More specifically, the solutions are no longer represented as a single value, but rather as a set of \textbf{non-dominated solutions}; these are solutions for which it is impossible to change the value of one of the variables without making at least one function evaluation worse. This set of solutions is known as the \textbf{Pareto Front}.   

\subsection{Computing the Pareto Front}
Many existing single-objective optimization algorithms have already been extended to work in the multi-objective case, such as Multi-Objective PSO (MOPSO) \cite{MOPSOPaper} (code available in \cite{MOPSOCode}), Multi-Objective Fireflies (MOFlies) \cite{MOFliesPaper}, and Multi-Objective Bats (MOBats) \cite{MOBatsPaper}. This work presents a similar extension to the RGO algorithm.

Inspecting the Pareto computation strategies in the existing algorithms revealed two main approaches, which we outline in this section. We extended RGO with both methods in order to test and compare them.

The first is primarily inspired by the MOBats implementation \cite{MOBatsCode}.  The basic idea is presented in pseudocode as follows.
\begin{algorithm}[h]
\caption{Pareto Approximation - No Checks}
\begin{algorithmic}[1]
\Input $\quad N$ number of points to find on the Pareto front; and  
       $F$ list of functions to optimize
\Output Set of $N$ points making up the Pareto approx
\Procedure{ParetoApproxNC}{}
\State ${P \gets []}$
\State ${i \gets 0}$
\While{ $i < N$}
	\State Create a random linear combination of the $F_k$
	\State Optimize this using single-objective optimization
	\State Add the position of the resulting optimum to $P$
	\State ${i \gets i + 1}$
\EndWhile
\Return $P$
\EndProcedure
\end{algorithmic}
\end{algorithm}  

This approach to Pareto approximation has one main accuracy drawback, in that it never performs any domination checks on the points added to the incremental front.  This leads to a possibility of points being added to the front which are dominated by other solutions in the approximation.  The accuracy of this approach with regards to the test suite used is discussed in the Results section below.

The second approach to Pareto computation is based off of the approach presented in MOPSO.  It is presented below as pseudocode.
\begin{algorithm}[h]
\caption{Pareto Approximation - With Checks}
\begin{algorithmic}[1]
\Input $\quad N$ number of iterations to run for; and  
       $F$ list of functions to optimize
\Output Set of points making up the Pareto approx
\Procedure{ParetoApprox}{}
\State ${P \gets}$ non-dominated initial positions
\State ${i \gets 0}$
\While{ $i < N$}
	\State ${curBest \gets}$ random point in $P$
	\State Use $curBest$ as the global best for this iteration
	\State Move all particles towards $curBest$ as in PSO
	\State ${L \gets}$ list of positions of all particles
	\State ${L \gets}$ non-dominated solutions in $L$
	\State ${P \gets [P; L]}$
	\State ${P \gets}$ non-dominated solutions in $P$
	\State ${i \gets i + 1}$
\EndWhile
\Return $P$
\EndProcedure
\end{algorithmic}
\end{algorithm}

In ParetoApprox, there is not a uniform probability for each point to be chosen as $curBest$.  Rather, solutions farther from the other points in $P$ are more likely to be chosen.  This leads to more exploration of the solution space, and helps avoid the particles getting stuck in a local optimum.

Specifically, in the MOPSO implementation, the $curBest$ is chosen through a grid system.  Specifically, the current set of non-dominated solutions is used to create a \textit{d}-dimensional grid, with \textit{d} being the number of functions in the list to optimize.  Each dimension of the grid is formed by taking the maximum and minimum evaluations of the points over the function corresponding to that dimension, and dividing it into \textit{n} even increments, with \textit{n} being the number of points currently on the Pareto front.  This forms a number line in each dimension.  Then, each point in the set can be associated with a particular cell in the grid \cite{MOPSOCode}.

In order to choose a $curBest$ from the current list of Pareto points, first a list is made of the occupied cells in the grid.  The probability of choosing each grid cell is inversely proportional to the number of points occupying it; that is to say, cells with more points are less likely to be chosen.  A grid cell is then selected according to the probabilities computed above; from this cell a particular point is chosen to be $curBest$ with uniform probability \cite{MOPSOCode}.  

This $curBest$ selection method, although more computationally intensive than a random selection from the list of Pareto points, leads to better results; choosing points farther away from the other points promotes more exploration of the solution space.  If the points were chosen with uniform probability, the chances would be higher to select a point in a solution cluster, as these points are more numerous.  This strategy helps decrease the frequency at which the search gets stuck in local minima.

In the MOPSO implementation, there is also a cap on the number of points which can be stored on the Pareto front approximation (chosen as 100 in their code \cite{MOPSOCode}).  This is to set a hard cap on the number of computations per iteration involving points in the set.  If at any point there are too many points stored in the set, points are deleted until the cap is reached; this deletion is also done using the grid approach, i.e. points in clusters are more likely to be removed.  This helps preserve the diversity of the solution set, and thus the spread and accuracy of the Pareto front approximation.  

The MOPSO approach, albeit more complex, leads to a more accurate representation of the Pareto front as it includes the domination checks, thus ensuring that the reported points do fit on the Pareto approximation.  The results of this method run over the selected test suite are included in the Results section below. 

\section{Multi-Objective Root Growth Optimization}

Extending RGO to MORGO involved some changes to the base algorithm.  In particular, the division into $mainRoots$, $lateralRoots$, and $agingRoots$ is central to the RGO logic, and it involves a total ordering of the roots, in their ranking by fitness values \cite{RGOPaper}.  This sorting is possible when there is one fitness value per root, but in the multi-objective case every solution on the Pareto front is equally considered ``best''; this total ordering is no longer possible.  In our adaptation of RGO, we consider an ordering of non-dominated sets, and chose the root categories based on these.  

The MORGO algorithm with MOPSO-style Pareto computation is included in pseudocode below.  

\begin{algorithm}[H]
\caption{MORGO}
\begin{algorithmic}[1]
\Input $\quad N$ number of iterations to run for; $m_n$ specified size of $mainRoots$; $l_n$ specified size of $lateralRoots$
\Output $P$ list of points on the Pareto front
\Procedure{MORGO}{}
\State Initialize $R$ list of root apices 
\State ${P \gets []}$
\State $i \gets 0$
\While{ $i < N$}
	\State ${P \gets nonDominated( [P; nonDominated( R)])}$
	\State $mainRoots$; $lateralRoots$; $agingRoots \gets rootSorting( R)$
	\State Choose a $curBest$ root from $P$
	\State Split and grow $mainRoots$ towards $curBest$
	\State Grow $lateralRoots$ towards $curBest$
	\State Prune random 25\% of $agingRoots$
	\State $R \gets$ surviving old roots, and new roots
	\State ${i \gets i + 1}$
\EndWhile
\State ${P \gets nonDominated( [P; nonDominated( R)])}$\\
\Return $P$
\EndProcedure
\end{algorithmic}
\end{algorithm}

Note that the specified sizes of $mainRoots$ and $lateralRoots$ are given as percentages of the size of the total root set, with values as specified in \cite{RGOPaper}.

The procedures used in MORGO are detailed below:
\begin{itemize}
\item Choosing $curBest$ is done by using the grid MOPSO approach detailed in ParetoApprox, with a slight modification: rather than creating the grid over the spread of function evaluations, it was done over the spread of the independent variables (the idea and result is equivalent as the original MOPSO grid, this approach just avoided some redundant computations with our implementation)
\item \textbf{nonDominated}: given a list of positions, this procedure returns those which are non-dominated.  This is ${O(n^2)}$, as for each position every other position in the list must be checked.
\item \textbf{rootSorting}: given a list of existing roots, this returns this list divided into $mainRoots$, $lateralRoots$, and $agingRoots$.  Since here a total ordering of the roots is impossible, sorting is done by non-dominated sets.  The $mainRoots$ are populated randomly from the non-dominated set; if this set becomes empty, the non-dominated set is computed again over the remaining roots.  Then, this same process applies to the $lateralRoots$.  The $agingRoots$ are the leftovers.
\end{itemize}

The new approach to root categorization is the most significant change from RGO to MORGO.  One downside to this approach is that here the domination checks occur many times per iteration; this is the most computationally intensive operation in the algorithm, and thus increases the runtime of MORGO.  There were some other minor changes to various parameter computations which relied on a single fitness value, however nothing else which changed the logic of the algorithm.  

This categorization strategy affected various aspects of the algorithm functionality.  In addition to the changes also present going from PSO to MOPSO (i.e. $curBest$ position selection), in RGO the operators are also computed taking into account the position of the global best, so in MORGO this too is affected.  As such, the computation for the operators might have lost their basis in biological reality; the ties to the actual root growth might be broken as the method is extended to the multi-objective case.  

This MORGO algorithm uses the Pareto computation as inspired by MOPSO.  We also created a version of MORGO using the ParetoApproxNC approach, labelled MRNC.  The pseudocode for this is not included here; it is simply a wrapper loop around RGO, running the single-objective optimization for the random linear combination of functions generated each iteration.    

\subsection{ Snap-to-bounds}

The algorithms other than the MORGO variants we coded were mostly taken from code provided by the various authors, available online at \cite{MOBatsCode}, \cite{MOPSOCode}.  These algorithms were mostly unchanged from their originals, in order to adequately compare with the MORGO implementations.  The one exception was MOFlies, which did not have code provided, and which we coded with the specifications provided in the paper \cite{MOFliesPaper}.  We also added functionality to both MOFlies and MOBats to take into account a constrained variable space which was not present in the initial implementations; this became vital when testing with functions which are not real-valued for all variable domains (such as the ZDT suite, detailed below).  This change was fairly minor, consisting of an added check to see if the bounds were exceeded, and, if they were, snap to the nearest bound.  MOPSO was unchanged, but since the initial code provided \cite{MOPSOCode} was a demo script, we had to write a wrapper function for it to work with the various test functions and parameters in our suite.


$\\$
The results of the two MORGO algorithms are detailed below.  All implementation details of all algorithms and test suites can be viewed in our code, available at \textit{URL elided for blind submission}.


\section{Testing and Results}

In order to properly validate our extensions of RGO, we performed a variety of tests with the goal of comparing MORGO and MRNC with other contemporary multi-objective optimization techniques. In this section, we will briefly outline our testing methodology and present some of our test results.

\subsection{Methodology}

A broad range of test functions, metrics, and other algorithms are required to properly situate a new approach in the literature. We drew inspiration from a few sources (\cite{RGOPaper}, \cite{ZDTFunsPaper}, \cite{MOFliesPaper}) to build an appropriate environment for testing MORGO.

First we will present our test metrics.

\begin{itemize}
\item \textbf{Run time:} our first test metric is the time taken to complete 100 iterations of the algorithm. This is a fairly standard metric for testing algorithms, as algorithms that are unreasonably slow are rarely used when much faster ones are available.

\item \textbf{Error:} this second test metric is not always available. We specifically chose some functions with known Pareto Fronts so that we could compute the average distance between the estimated and actual fronts. 

\item \textbf{Spread:} this final metric rounds out the picture of the performance of the algorithms. By computing the standard deviation of the points computed, we have a measure of diversity of the estimated Pareto Front.
\end{itemize}

Note that the numerical results presented were obtained by averaging metric evaluations over 20 runs of each test.

% By considering each of these metrics, we can identify strengths and weaknesses in each of the approaches.

\subsection{Test Suites}

In this section, we will briefly outline the test functions we used. Some fairly standard functions used for testing multi-objective optimization techniques are the ZDT test functions, of which we selected ZDT1, ZDT2, ZDT3, ZDT4, and ZDT6, from \cite{ZDTFunsPaper}. These functions are outlined below.

\begin{align*}
\text{ZDT1}: 	&	& f_1(x) & = x_1 \\
	  		&	& f_2(x) & = g(x) \floor[\Big]{1 - \sqrt{x_1/g(x)}} \\
where: 		& 	& g(x) & = 1 + 9 \left( \textstyle\sum\nolimits_{i=2}^{n} x_i \right)/(n-1) \\
\\
\text{ZDT2}: 	&	& f_1(x) & = x_1 \\
	  		&	& f_2(x) & = g(x) \floor[\Big]{1 - (\tfrac{x_1}{g(x)}) ^2} \\
where: 		& 	& g(x) & = 1 + 9 \left( \textstyle\sum\nolimits_{i=2}^{n} x_i \right)/(n-1) \\ 
\\
\text{ZDT3}: 	&	& f_1(x) & = x_1 \\
	  		&	& f_2(x) & = g(x) \floor[\Big]{1 - \sqrt{x_1/g(x)} - \tfrac{x_1}{g(x)} \sin(10 \pi x_1) } \\
where: 		& 	& g(x) & = 1 + 9 \left( \textstyle\sum\nolimits_{i=2}^{n} x_i \right)/(n-1) \\ 
\\
\text{ZDT4}: 	&	& f_1(x) & = x_1 \\
	  		&	& f_2(x) & = g(x) \floor[\Big]{ 1 - \sqrt{x_1 / g(x)}} \\
where: 		& 	& g(x) & = 1 + 10(n - 1) + \textstyle\sum\nolimits_{i=2}^n{\left[ x_i^2 - 10 cos(4 \pi x_i ) \right]} \\ 
\\
\text{ZDT6}: 	&	& f_1(x) & = 1 - e^{-4x_1} \sin^6(6 \pi x_1) \\
	 		&	& f_2(x) & = g(x) \left[ 1 - \left( \tfrac{f_1(x)}{g(x)} \right)^2 \right] \\
where: 		& 	& g(x) & = 1 + 9 \left[ \frac{\textstyle\sum\nolimits_{i=2}^{n} x_i}{n-1} \right]^{\frac{1}{4}}
\end{align*}

These functions all have large dimension (the independent variable $x$ has 30 elements), and small domain (each $x_i \in [0, 1]$, the sole exception being ZDT4, where $x_i \in [-5, 5]$ for $i > 1$). The ZDT functions form the test suite with known Pareto Fronts, so errors can be calculated. In addition, the Pareto Fronts of the ZDT functions all have interesting features that test the effectiveness of multi-objective optimization algorithms. Namely, \cite{ZDTFunsPaper}:

\begin{itemize}
\item \textbf{ZDT1}: the Pareto-optimal front here is simple convex. 
\item \textbf{ZDT2}: a counterpart to ZDT1, the Pareto-optimal front here is nonconvex.
\item \textbf{ZDT3}: this function tests the ability of the optimization algorithms to deal with multiple disjoint fronts. Here, the Pareto-optimal front is comprised of many disjoint convex parts.
\item \textbf{ZDT4}: here, the ability of the optimization algorithms to deal with multimodality is put to the test; the Pareto-optimal front for ZDT4 consists of $21^9$ local fronts.
\item \textbf{ZDT6}: in this test, the search space is nonuniform. The Pareto-optimal solutions are nonuniformly distributed along the Pareto front, and the density of the solutions is lowest near the Pareto-optimal front and highest further from it.
\end{itemize}

Our second test suite is comprised of the Schwefel 1.2, Rosenbrock, and Ackley functions. These were used by He et al in \cite{RGOPaper}; the independent variables are 2-dimensional, but with much wider domains. They are shown below.

\begin{align*}
\text{Schwefel 1.2}: 	&	& f_1(x)	& = x_1 \\
	  			&	& f_2(x)	& = \sum_{i=1}^{2} \left( \sum_{j=1}^{i} x_j \right) ^2 \\
\\
\text{Rosenbrock}: 	&	& f_1(x)	& = x_1 \\
	  			&	& f_2(x)	& = 100 \left( x_1^2 - x_{2}\right)^2 + \left( 1 - x_1 \right)^2 \\
\\
\text{Ackley}: 		&	& f_1(x)	& = x_1 \\
	  			&	& f_2(x)	& = 20 + e - 20 e^{-0.2 \sqrt{\frac{1}{2} \sum_{i=1}^{2} x_i^2}} \\
				&	&	    	& \quad - e^{\frac{1}{2} \sum_{i=1}{2} \cos(2 \pi x_i)} 
\end{align*}

In this test suite, the Pareto Front is not known, so we cannot perform error calculations. We selected these in particular since they pose different challenges for heuristic algorithms. Namely, the Rosenbrock function, pictured below, has a very slight slope, and so optimization algorithms need to be aggressive in order to find optima in reasonable time. On the other hand, the Ackley function, pictured as well, has many local optima, so an optimization algorithm would need to avoid getting stuck in these while searching for the global optimum.

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{rosenbrock_surface_plot}
\caption{Rosenbrock function.}
\label{fig:rossurfplot}
\end{figure}

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{ackley_surface_plot}
\caption{Ackley function.}
\label{fig:ackleysurfplot}
\end{figure}

\subsection{Results}

We will now present and discuss select test results. Let us consider our first figure: a visual representation of the results of running the algorithms on the ZDT1 test function.

\begin{figure}[h]
\includegraphics[width=0.5\textwidth]{ZDT1CompPlot_newIcons}
\caption{Visual results for ZDT1.}
\label{fig:zdt1visual}
\end{figure}

In this figure, we can see that MOPSO is by far the most effective algorithm in terms of spread and error, as the Pareto Front that it estimates closely matches the actual Pareto Front. Curiously, MORGO also estimates the correct shape, however the estimated values are relatively far from the actual front. The MRNC algorithm produces a front that is quite close to the actual one, however the spread of the points is too small to be meaningful. The other two algorithms quite simply fail. The table below summarizes numerical values for all of our test metrics.  Runtime is measured in seconds.

%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{ZDT1TimingPicBIG}
%\caption{Timing results for ZDT1.}
%\label{fig:zdt1timing}
%\end{figure}

\begin{table}[htp]
\centering
 \begin{tabular}{||c c c c c c||} 
 \hline
 & MOPSO & MORGO & MRNC & MOFlies & MOBats \\
 \hline \hline
 Runtime &  7.12 &  31.05 & 1.67 & 77.42 & 0.26 \\
 \hline
 Error & 0.11 & 1.76 & 0.10 & 1.69 & 2.07 \\
 \hline
 Spread & 0.32 & 0.45 & 0.12 & 0.24 & 0.76 \\
 \hline
\end{tabular}
\caption{ZDT1 aggregate results.}
\label{tab:zdt1agg}
\end{table}

\vspace*{-\baselineskip}

In terms of timing, the ParetoApproxNC algorithms were the fastest, but we can see from Fig \ref{fig:zdt1visual} that they do not produce good fronts. 

MORGO is quite slow; this is due to the costly nature of the non-domination computations, as previously discussed. It is worth noting that the reason MRNC and MOBats run so quickly is that they simply do not perform these costly checks. MOPSO manages to skirt around the majority of these costly computations by only computing non-dominated solutions once per iteration \cite{MOPSOCode}, whereas MORGO performs many more non-domination checks per iteration (for instance, when building ${mainRoots}$ and ${lateralRoots}$ lists). 

We cannot judge the algorithms based on timing alone. Table \ref{tab:zdt1agg} also includes error and spread results. Taking all metrics into consideration, we argue that MOPSO performs the best out of all of the algorithms, as it achieves low error while maintaining a healthy spread among its estimated points. The MRNC algorithm produces points near to the Pareto Curve, though the spread is quite small. We see that the MORGO algorithm finds points that are far from the Pareto Curve, though the spread of its points is comparable to that of MOPSO. These results are far more meaningful when one considers Fig \ref{fig:zdt1visual}; we can see that even though MORGO finds points that are far from the Pareto Front, the shape of the Pareto Curve that it computes closely matches the shape of the true Pareto Curve. 

Now, let us consider the Rosenbrock test function.

%We will now consider the Rosenbrock test function. First, a visual representation of the results:

\begin{figure}[h]
\includegraphics[width=0.5\textwidth]{RosenbrockCompPlot_newIcons}
\caption{Visualization of Rosenbrock results.}
\label{fig:rosvis}
\end{figure}

Here, we see that most of the algorithms performs reasonably well. The most lackluster results are again for the MRNC and MOBats algorithms, as the Pareto Fronts they compute are all relatively close to $f_2(x) = 0$. MOPSO, MORGO, and MOFlies each compute reasonably similar Pareto Fronts, though there is no way of knowing if this front is accurate, as we do not have access to the true front.

Table \ref{tab:rosresults} summarizes timing and spread results for the Rosenbrock function. Here, we see that MRNC and MOBats have a very small spread of points. MOPSO has the best spread, followed by MOFlies. MORGO struggles a little with respect to this metric, which can be seen in Fig \ref{fig:rosvis}; many of the points computed by MORGO are near to each other, around $f_1(x) = -20$. The runtime results follow the same trends visible in Table \ref{tab:zdt1agg}, with similar conclusions being drawn.

%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{RosenbrockSpreadFig}
%\caption{Spread results for Rosenbrock.}
%\label{fig:rosspread}
%\end{figure}

\begin{table}[htp]
\centering
 \begin{tabular}{||c c c c c c||} 
 \hline
 & MOPSO & MORGO & MRNC & MOFlies & MOBats \\
 \hline \hline
 Runtime & 14.91 & 55.33 & 1.11 & 62.59 & 0.17 \\
 \hline
 Spread & 1.316e7 & 0.346e7 & 0.004e8 & 0.843e7 & 0.013e8 \\
 \hline
\end{tabular}
\caption{Rosenbrock aggregate results.}
\label{tab:rosresults}
\end{table}

\vspace*{-\baselineskip} 
\vspace*{-\baselineskip} 

\subsection{Data Tables}

For posterity, we will include and briefly discuss the rest of our test results. The previous sections dealt with some case by case analysis of results, and served to highlight certain aspects of each of the approaches. Here, we will present aggregate test results for the remaining functions.

\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c||} 
 \hline
 & MOPSO & MORGO & MRNC & MOFlies & MOBats \\
 \hline \hline
 Runtime & 2.8149 & 22.7182 & 1.7169 & 69.7665 & 0.2429 \\
 \hline
 Error & 1.1444 & 2.6857 & 0.2559 & 0.1384 & 3.1627 \\
 \hline
 Spread & 0.0381 & 0.3025 & 0.1444 & 0.0007 & 0.5423 \\
 \hline
\end{tabular}
\caption{ZDT2 Aggregate Test Results.}
\end{table}

\vspace*{-\baselineskip} 

\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c||} 
 \hline
 & MOPSO & MORGO & MRNC & MOFlies & MOBats \\
 \hline \hline
 Runtime & 6.2209 & 25.7993 & 1.9305 & 104.0602 & 0.2726 \\
 \hline
 Error & 0.0894 & 1.8971 & 0.0901 & 1.8242 & 1.8095 \\
 \hline
 Spread & 0.4115 & 0.5240  &  0.1991  &  0.0793   & 0.7095 \\
 \hline
\end{tabular}
\caption{ZDT3 Aggregate Test Results.}
\end{table}

\vspace*{-\baselineskip} 

\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c||} 
 \hline
 & MOPSO & MORGO & MRNC & MOFlies & MOBats \\
 \hline \hline
 Runtime & 2.8162 & 14.7525 & 1.7721 & 95.5504 & 0.2898 \\
 \hline
 Error & 279.0812 & 304.5452 & 51.7851 & 202.2923 & 347.5845 \\
 \hline
 Spread & 4.9536 & 59.4011 & 50.3510 & 5.9848 & 46.2826 \\
 \hline
\end{tabular}
\caption{ZDT4 Aggregate Test Results.}
\end{table}

\vspace*{-\baselineskip} 

\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c||} 
 \hline
 & MOPSO & MORGO & MRNC & MOFlies & MOBats \\
 \hline \hline
 Runtime & 4.7581  & 18.3249   & 1.7394 &  84.1429   & 0.2854 \\
 \hline
 Error & 0.9906  &  6.1075  &  3.9281  &  2.0893  &  6.2065 \\
 \hline
 Spread & 0.6562  &  0.4045  &  0.8700   & 1.0237  &  0.8525 \\
 \hline
\end{tabular}
\caption{ZDT6 Aggregate Test Results.}
\end{table}

\vspace*{-\baselineskip} 

\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c||} 
 \hline
 & MOPSO & MORGO & MRNC & MOFlies & MOBats \\
 \hline \hline
 Runtime & 11.0386  & 23.0775  &  1.7090  & 138.7963  & 0.3797 \\
 \hline
 Spread & 1.7039e3  &  2.6965e3  &  0.2841e3  &  1.8326e3  &  0.4739e3 \\
 \hline
\end{tabular}
\caption{Schwefel 1.2 Aggregate Test Results.}
\end{table}

\vspace*{-\baselineskip} 

\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c||} 
 \hline
 & MOPSO & MORGO & MRNC & MOFlies & MOBats \\
 \hline \hline
 Runtime & 7.0117  &  5.1668  &  1.0049  &  50.6646  &  0.1969 \\
 \hline
 Spread & 6.7837  &  4.9886  & 10.6133  &  7.2818  &  8.2169 \\
 \hline
\end{tabular}
\caption{Ackley Aggregate Test Results.}
\end{table}

%\vspace*{-\baselineskip} 

\subsection{Summary of Results}

The aggregate timing, error, and spread results shown above lead us to claim that MOPSO is probably the best multi-objective optimization algorithm, with MORGO close behind, at least in small dimensions. The lackluster performance of MRNC and MOBats with respect to both the spread and error metrics suggests that the ParetoApproxNC method is inferior to ParetoApprox. Finally, though it does produce good results in low dimensions, MOFlies is practically unusable due to how slow it is.

In conclusion, MOPSO seems to be the best algorithm overall of those tested.  Also, the contest between ParetoApproxNC and ParetoApprox seems to have been decisively won by ParetoApprox; thus, algorithms implemented with the ParetoApproxNC method could be improved by reimplementing them with ParetoApprox.  

Although it is unfortunate that MORGO did not perform better in these tests, there is room for potential improvement to this algorithm, which are addressed below.   

\section{Future Work}

There are still a few avenues to explore for improvements to MORGO. One such avenue is the testing of various initialization schemes; preliminary results suggest that initialization of starting root apex positions in a grid or some other distribution based on sampling of the search space could lead to improvements to MORGO's performance (these schemes foster the exploration aspect of heuristic optimization). These schemes, if effective, would stand to benefit all optimization algorithms, and are not exclusive to MORGO. 

We will also test the effect of the parameter values in the MORGO algorithm.  As mentionned, various parameters for RGO were missing from the description in \cite{RGOPaper} and thus were chosen empirically; parameter optimization of these could improve the results of the MORGO algorithm.  In particular, it seems the offset between the Pareto-optimal front and the front computed (for the ZDT suite) could be a result of this non-optimal parameter selection.  

The MORGO code could also be more streamlined, as we have not yet made use of Matlab's support for code optimization. This could help reduce the runtime, which was MORGO's other main drawback.

Overall, this research is not dead and these are various avenues for future work.  

\Urlmuskip=0mu plus 1mu\relax
\bibliographystyle{IEEEbib}
\bibliography{template}

\end{document}